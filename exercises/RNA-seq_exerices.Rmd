---
title: "Practive with RNA-seq"
output: html_notebook
---

```{r setup, include  = F}
library(knitr)
library(tidyverse)
opts_knit$set(root.dir = '/data/swamyvs/BIOF045-NGS-Data-Analysis-Day-3/') #***CHANGE THIS TO THE RNA-seq DIRECTORY****
```

- we're going to run most of your bash commands through an R notebook; its a good way to make sure you keep track of what commands you're using,  and you can makes notes better than a bash script 
```{bash}
echo $PWD
```


## Get annotation 
- First, lets get some annotation.
- The data we'll be working with is from this study: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4057123/
- this is data is from human, so lets download some annotation for data. 
- transcript fasta: ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.transcripts.fa.gz
- genome: ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/GRCh38.primary_assembly.genome.fa.gz
- gtf: ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gtf.gz
- There's two general best practices for storing annotations - keep a single folder on your computer that has all your annotation, or keep a separate folder for each project. 
- I generally keep a separte folder for each project, which requires more space, but makes your code more portable, as annotation is contained within your project
```{bash }
mkdir -p references
wget -O references/transcripts.fa.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.transcripts.fa.gz
wget -O references/human_genome_grch38.fa.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/GRCh38.primary_assembly.genome.fa.gz
wget -O references/transcript_annotation.gtf.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gtf.gz

```

## Building an index
- I'm not goint to cover how to download salmon, because the developers have good documentation on how to do so, and we have it pre-installed on this server.


```{bash}
salmon --help

```

- First, we make the decoy files need for building the index
```{bash}
zcat references/human_genome_grch38.fa.gz | grep "^>"  -| cut -d " " -f 1 | sed  -e 's/>//g'  > references/decoys.txt # get names of chromosomes 
zcat references/transcripts.fa.gz references/human_genome_grch38.fa.gz > references/gentrome.fa # merge two fastas together

```


- try writing out what the command would be for generating the index. try running but stop it once it gets going as it takes about an hour to build.

```
```
- the index for the class is at '/data/day3_RNA-seq/salmon_human_index/'


- Now we can quantify our samples.
- try writing out a command for running salmon in quant mode and running it
- fastqs are stored in  the folder /data/day3_RNA-seq/fastqs/

```{bash}

```


- lets take a look at the output of this step 
- I've quantified data for some samples, available at '/data/day3_RNA-seq/fastqs/' ; We'll specifically be looking at the folder for `SRR1039521`
```{bash}
cd /data/day3_RNA-seq/quant/SRR1039521
ls
```

- quant.sf contians the actualy quantification data
- aux_info/meta_info.json contains important information about the how the data was map. Lets take a look at it . 
`cat` the file, or look at with `less`
```{bash}
cat aux_info/meta_info.json 
```

- always take a look at the mapping rate for your samples. You generally want a mapping rate above 70%, ideally 80%

- We'll be using the rest of the data in the `quant` folder for the rest of this exercise
- This grabs the file paths for you
```{r}
quant_files <- list.files(pattern = '/data/day3_RNA-seq/quant', pattern = 'quant.sf', recursive = T, full.names = T )
```

- read the gtf we downloaded into R with `rtracklayer::readGFF`. Use tidyverse functions to select the transcript_id and gene_id column, and use `distinct` to remove duplicate rows. This will be our `tx2gene` for `tximport`

- use the `quant_files` vector and the `tx2gene` we generated to load our quantification data into R

```{r}
library(tximport)
```

- take a look at the `abundance` and `counts` object within the `tximport` object you created. 
- for reference, `abundance` refers to TPM values, and `counts` refers to the raw number of RNA-seq reads

```{r}

```

- load this into `DESeq2` with `DESeqDataSetFromTximport`

```{r}
library(DESeq2)
```

- From here we can move straight into the analysis

- filter out genes whose total count across all samples is less than 16
```{r}

```

- normalize for library size with `estimateSizeFactors`

```{r}

```

- account for unwanted variation with `estimateDispersions`

```{r}

```

- created an object with transformed counts with `rlog`

```{r}

```

- plot a PCA with plotPCA

```{r}

```

- make a correlation heat map with the `pheatmap` package. Remember that you can extract data from DESeq objects with `assay` and generate a correlation matrix with `cor`

```{r}
library(pheatmap)
```

- test for differential expression via an LRT with `nbinomLRT`

```{r}

```

- get the results of the test with `results`

```{r}

```

- select differentially expressed genes. Use a padj cutoff of .05 and a log2fc cutoff of 1

```{r}

```

- make a volcanoplot with `EnhancedVolcano::EnhancedVolcano`

```{r}
library(EnhancedVolcano)
```

- select the top 20 genes from the DGE results and make a heatmap with `pheatmap`

```{r}
library(pheatmap)
```

- use `clusterProfiler::enrichGO` to calculate gene set enrichment.

```{r}
library(clusterProfiler)
```

- - use `clusterProfiler::dotplot` to visualize the results of GSEA

```{r}

```

