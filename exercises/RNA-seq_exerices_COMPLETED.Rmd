---
title: "Practive with RNA-seq"
output: html_notebook
---

```{r setup, include  = F}
library(knitr)
library(tidyverse)
opts_knit$set(root.dir = "/home/vinay/BIOF045-NGS-Data-Analysis-Day-3") #***CHANGE THIS TO THE RNA-seq DIRECTORY****
```

- we're going to run most of your bash commands through an R notebook; its a good way to make sure you keep track of what commands you're using,  and you can makes notes better than a bash script 
```{bash}
echo $PWD
```


## Get annotation 
- First, lets get some annotation.
- The data we'll be working with is from this study: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4057123/
- this is data is from human, so lets download some annotation for data. 
- transcript fasta: ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.transcripts.fa.gz
- genome: ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/GRCh38.primary_assembly.genome.fa.gz
- gtf: ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gtf.gz
- There's two general best practices for storing annotations - keep a single folder on your computer that has all your annotation, or keep a separate folder for each project. 
- I generally keep a separate folder for each project, which requires more space, but makes your code more portable, as annotation is contained within your project
```{bash}
mkdir -p references
wget -O references/transcripts.fa.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.transcripts.fa.gz
wget -O references/human_genome_grch38.fa.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/GRCh38.primary_assembly.genome.fa.gz
wget -O references/transcript_annotation.gtf.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gtf.gz

```

## Building an index
- I'm not going to cover how to download salmon, because the developers have good documentation on how to do so, and we have it pre-installed on this server.


```{bash}
salmon --help

```

- First, we make the decoy files need for building the index
```{bash}
zcat references/human_genome_grch38.fa.gz | grep "^>"  -| cut -d " " -f 1 | sed  -e 's/>//g'  > references/decoys.txt # get names of chromosomes 
zcat references/transcripts.fa.gz references/human_genome_grch38.fa.gz > references/gentrome.fa # merge two fastas together

```

- try writing out what the command would be for generating the index. try running but stop it once it gets going as it takes about an hour to build.

```
salmon index -t references/gentrome.fa -d references/decoys.txt -i  salmon_index
```
- the index for the class is at '/data/day3_RNA-seq/salmon_human_index/'


- Now we can quantify our samples.
- try writing out a command for running salmon in quant mode and running it
- fastqs are stored in the folder /data/day3_RNA-seq/fastqs/

```{bash}
salmon quant  --index /data/day3_RNA-seq/salmon_human_index/ --libType A -1  /data/day3_RNA-seq/fastqs/SRR1039520_1.fastq -2 /data/day3_RNA-seq/fastqs/SRR1039520_2.fastq  --output SRR1039520
 
```
- lets take a look at the output of this step 
- I've quantified data for some samples, available at '/data/day3_RNA-seq/fastqs/' ; We'll specifically be looking at the folder for `SRR1039521`
```{bash}
cd /data/day3_RNA-seq/quant/SRR1039521
ls
```

- quant.sf contians the actualy quantification data
- aux_info/meta_info.json contains important information about the how the data was map. Lets take a look at it . 
`cat` the file, or look at with `less`
```{bash}
cat aux_info/meta_info.json 
```

- always take a look at the mapping rate for your samples. You generally want a mapping rate above 70%, ideally 80%

- We'll be using the rest of the data in the `quant` folder for the rest of this exercise
- This grabs the file paths for you
```{r}
quant_files <- list.files(path = '/data/day3_RNA-seq/quant', pattern = 'quant.sf', recursive = T, full.names = T )
quant_files

```

- read the gtf we downloaded into R with `rtracklayer::readGFF`. Use tidyverse functions to select the transcript_id and gene_id column, and use `distinct` to remove duplicate rows. This will be our `tx2gene` for `tximport`

```{r}
library(tidyverse)
gtf <- rtracklayer::readGFF('/data/day3_RNA-seq/references/transcript_annotation.gtf.gz')
tx2gene <- gtf %>% 
    filter(type == 'transcript') %>% 
    select(transcript_id, gene_id) %>% 
    distinct
```

- use the `quant_files` vector and the `tx2gene` we generated to load our quantification data into R

```{r}
library(tximport)
txi <- tximport(files = quant_files,
                type = 'salmon', 
                tx2gene = tx2gene
                )
```

- take a look at the `abundance` and `counts` object within the `tximport` object you created. 
- for reference, `abundance` refers to TPM values, and `counts` refers to the raw number of RNA-seq reads

```{r}
names(txi)
sample_names <- quant_files %>% str_split('/') %>% sapply(function(x) x[5])
colnames(txi$abundance) <-sample_names
colnames(txi$counts) <- sample_names
colnames(txi$length) <- sample_names
```

- load this into `DESeq2` with `DESeqDataSetFromTximport`

```{r}
library(DESeq2)
sample_table <- read_csv('src/sample_table.csv')
dds <- DESeqDataSetFromTximport(txi,sample_table, ~treatment )
getwd()
```


```{r}
library(DESeq2)

```

- From here we can move straight into the analysis

- filter out genes whose total count across all samples is less than 16

```{r}
dim(dds)
gene_sums <-   rowSums(assay(dds))
gene_sums_above_16 <- gene_sums > 16
dds <- dds[gene_sums_above_16 , ]

```

- normalize for library size with `estimateSizeFactors`

```{r}
dds <- estimateSizeFactors(dds)
```

```{r}
colSums(assay(dds))
```
- account for unwanted variation with `estimateDispersions`
```{r}
dds <- estimateDispersions(dds)

```
- created an object with transformed counts with `rlog`
```{r}
rlds <- rlog(dds)

```

- plot a PCA with plotPCA
```{r}
plotPCA(rlds, intgroup= 'treatment', returnData=T)
pca_Data <-  plotPCA(rlds, intgroup= 'treatment', returnData=T)
```

- make a correlation heat map with the `pheatmap` package. Remember that you can extract data from DESeq objects with `assay` and generate a correlation matrix with `cor`

```{r}
library(pheatmap)
mat <- assay(rlds)
cor_mat <- cor(mat)
rownames(sample_table) <- sample_table$sample
pheatmap(cor_mat)
```


- test for differential expression via an LRT with `nbinomLRT`

```{r}

dds <- nbinomLRT(dds, full = design(dds), reduced = ~1)
diff_exp_results <- results(dds) %>% as.data.frame %>%
    rownames_to_column('gene_id') %>%
    filter(abs(log2FoldChange) > 2, padj < .05 )

id2gene <- gtf %>% filter(type  == 'gene') %>% 
    select(gene_id, gene_name) %>% distinct

diff_exp_gene_names <- id2gene %>% filter(gene_id %in% diff_exp_results$gene_id) %>% pull(gene_name)
diff_exp_gene_names
```
- use `clusterProfiler::enrichGO` to calculate gene set enrichment.

```{r}
library(clusterProfiler)
gse <- enrichGO(gene = diff_exp_gene_names,
                OrgDb = 'org.Hs.eg.db', 
                keyType = 'SYMBOL',
                ont = 'BP'
                )
dotplot(gse)
```


- make a volcanoplot with `EnhancedVolcano::EnhancedVolcano`

```{r}
library(EnhancedVolcano)
EnhancedVolcano(diff_exp_results, 
                lab = rownames(diff_exp_results),
                FCcutoff = 2, 
                x = 'log2FoldChange',
                y = 'pvalue')

```

- select the top 20 genes from the DGE results and make a heatmap with `pheatmap`

```{r}
library(pheatmap)
top20 <-  diff_exp_results %>% arrange(padj) %>% .[1:20, ] %>%
    pull(gene_id)
mat <-  assay(rlds)
pheatmap(mat[top20,])
```

```{r}

```



- - use `clusterProfiler::dotplot` to visualize the results of GSEA

```{r}

```

